\chapter{Data Preparation}

\begin{figure}[hbtp]
	\centering
	\includegraphics[width=0.5\textwidth]{./images/CRISPDM_3.png}
	\caption{CRISP-DM - Data Preparation}
	\label{CRISPDM_3}
\end{figure}

In questa fase si andranno a modellare i dati presenti nel dataset al fine di poter essere utilizzabili ai fini del processo del CRISP-DM.

\section{Criteri di Inclusione/Esclusione dei dati}

La totalità dei dati presenti nel dataset verrà utilizzata per il processo di KDD; non verrà fatta nessuna esclusione di istanza.

\section{Selezione dei dati}

\section{Campionamento}
Visto l'esiguo quantitativo di istanze disponibili, non è stato fatto nessun campionamento.

\section{Feature Selection}

Per quanto riguarda la fase di feature selection, si è deciso di effettuare una selezione tra gli attributi presenti in quanto molti di questi presentano valori nulli nella maggior parte delle istanze del dataset. Questo potrebbe, non solo non portare benefici al processo, ma anche peggiorare l'efficienza dell'algoritmo.

Come algoritmo di feature selection, si è scelto il \textit{CfsSubsetEval}, il quale valuta il miglior subset degli attributi considerando la singola correlazione di ognuno con l'attributo di classe. Si sceglierà il subset con la più alta correlazione con l'attributo di classe, ma allo stesso tempo, con una bassa correlazione con gli altri attributi. La ricerca nello spazio del subset degli attributi viene realizzata attraverso la strategia best first cercando di avvicinarsi ad un risultato ottimale in maniera greedy tagliando lo spazio di ricerca con la tecnica del backtracking.\cite{Hall1998}

L'algoritmo può operare in tre modi:
\begin{itemize}
	\item partire da un insieme di feature vuoto e incrementarlo aggiungendo le feature più predittive;
	\item partire dall'insieme contenente tutte le feature e ridurlo eliminando le feature meno predittive;
	\item partire da un qualsiasi punto e muoversi in entrambe le direzioni aggiungendo e rimuovendo feature.
\end{itemize}

\section{Data Cleaning}

\section{Construct Data}

Al fine aumentare il quantitativo informativo del dataset, sono state generate nuove istanze attraverso l'utilizzo dell'algoritmo \textit{SMOTE}. L'algoritmo permette di ricampionare il dataset in maniera supervisionata utilizzando la \textbf{S}ynthetic \textbf{M}inority \textbf{O}versampling \textbf{TE}chnique. 
\cite{Chawla02smote:synthetic}


SMOTE: A State-of-the-Art Resampling Approach 

SMOTE stands for Synthetic Minority Oversampling Technique. 
It is a technique designed by Chawla, Hall, \& Kegelmeyer  in 2002.
It combines Informed Oversampling of the minority class with Random Undersampling        of the majority class.
SMOTE currently yields the best results as far as re-sampling and modifying the probabilistic estimate techniques go (Chawla, 2003).

SMOTE’s Informed Oversampling Procedure II

For each minority Sample
	Find its k-nearest minority neighbours
	Randomly select j of these neighbours
	Randomly generate synthetic samples along the lines joining the minority sample and its j selected neighbours
(j depends on the amount of oversampling desired) 


Difetti:

Overgeneralization
SMOTE’s procedure is inherently dangerous since it blindly generalizes the minority area without regard to the majority class.
This strategy is particularly problematic in the case of highly skewed class distributions since, in such cases, the minority class is very sparse with respect to the majority class, thus resulting in a greater chance of class mixture.

Mancanza di flessibilità
The number of synthetic samples generated by SMOTE is fixed in advance, thus not allowing for any flexibility in the re-balancing rate.

NAME
weka.filters.supervised.instance.SMOTE

SYNOPSIS
Resamples a dataset by applying the Synthetic Minority Oversampling TEchnique (SMOTE). The original dataset must fit entirely in memory. The amount of SMOTE and number of nearest neighbors may be specified. For more information, see 

Nitesh V. Chawla et. al. (2002). Synthetic Minority Over-sampling Technique. Journal of Artificial Intelligence Research. 16:321-357.

OPTIONS
classValue -- The index of the class value to which SMOTE should be applied. Use a value of 0 to auto-detect the non-empty minority class.

nearestNeighbors -- The number of nearest neighbors to use.

percentage -- The percentage of SMOTE instances to create.

randomSeed -- The seed used for random sampling.

\section{Integrate Data}
La fase di integrazione dati è utile quando si stanno analizzando dati che possono essere descritti meglio con informazioni provenienti da altri database. In questa fase si integrano quindi i dati provenienti da diverse sorgenti al fine di ottenere una base di dati più popolata e quindi più dettagliata. L'integrazione è utile anche quando le informazioni a disposizione sono poco e vanno quindi espanse con dati esogeni.
Non è stato necessario creare attributi derivati.

\section{Format Data}
Il dataset a disposizione era in formato .txt avente come delimitatore dei dati lo spazio e l'andata a capo come terminazione di una istanza. Questo ha reso necessario una conversione del dataset nel formato \textit{ARFF} in modo tale da poter essere utilizzato in Weka.
